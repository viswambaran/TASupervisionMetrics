---
title: "Supervisory Resource Allocation Report"
author: "Dylan Viswambaran"
date: "27/11/2023"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE, 
                      message = FALSE)
```


```{r load_data}

source("R/main.R")

```
This report outlines an overview of the top insurance industry performers, noting various measures such as Gross Written Premium, Net Written Premium,  Gross Claims Incurred, as well as various other ratios.  K-means clustering has also been used a machine learning tool to clusters and predict claims.  


## Firms Overview 

### Metrics Overview 

```{python}
import pandas as pd 


df_overview =  pd.read_csv("general.csv")
summary = df_overview.pivot_table(index='Firms', columns='Variable', values ='value', fill_value=0).describe()

```


```{r}
library(reticulate)
py$summary %>% 
  kable() %>% 
  kable_styling()

```



To get an idea of the firms in the data. Below is a section to give a overview of the largest firms, how their profile evolves and any firms that stand out compared to its peers. 



### Gross Written Premium

Focusing on the latest year here are the top 5 firms by their Gross Written Premium (GWP):  
```{r GWP }

## Previous years average for comparison 
prevtop5Avg <-
  condensed_table_changes_long %>%
  # filter(Year == max(Year) - 1) %>% 
  group_by(Metric, Year) %>% 
  slice_max(value, n = 5) %>% 
  summarise(Average = mean(value, na.rm = TRUE)) %>% 
  ungroup()

GWPAvg <- prevtop5Avg %>% 
  filter(Metric == "GWP (£m)") %>% 
  slice_max(Year, n = 2) 

## Latest year chart and table 



latestTop5GWP <- condensed_table_changes_long %>%
  filter(Year == max(Year),
         Metric == "GWP (£m)") %>%
  slice_max(value, n = 5)



## Plot
latestTop5GWP %>%
    ggplot(aes(x = reorder(Firms, -value),
               y = value)) +
    geom_bar(stat = "identity",
             position = position_dodge2(),
             fill = boe_brand_main$boe_aqua) +
    boeCharts::theme_boe_identity_md() +
    scale_y_continuous(labels = label_currency()) +
    labs(x = "Firm",
         y = "GWP (£m)",
         title = "Top 5 Firms by Gross Written Premium (2020)") + 
    coord_flip() +
    geom_hline(yintercept = GWPAvg$Average[1], linetype = "dashed", color = "red") +
    annotate("text", x = Inf, y = GWPAvg$Average[1], label = "2020 Average (Top 5)", color = "red", hjust = -0.75, vjust = 3.5) +
    geom_hline(yintercept = GWPAvg$Average[2], linetype = "dashed", color = "yellow") +
    annotate("text", x = Inf, y = GWPAvg$Average[2], label = "2019 Average (Top 5)", color = "yellow", hjust = -0.73, vjust = 8.5)


## Table
latestTop5GWP %>% 
  select(-Metric) %>% 
  rename(`£mn` = value) %>% 
  kable(caption = "Top 5 Firms by Gross Written Premium") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = TRUE)
  

  


```
Looking at firm sizes on the average over the past few years. This will give an indication of the size of the firm over time and not just focusing on a particularly good (or bad) year. 

```{r GWPAvg}

top5AverageGWP <- condensed_table_changes_long %>%
  group_by(Firms, Metric) %>%
  summarise(Average = mean(value)) %>%
  ungroup() %>%
  filter(Metric == "GWP (£m)") %>%
  slice_max(Average, n = 5)


## Plotting average 
top5AverageGWP %>% 
  ggplot(aes(x = reorder(Firms, -Average),
             y = Average)) +
  geom_bar(stat = "identity",
           position = position_dodge2(),
           fill = boe_brand_main$boe_aqua) +
  boeCharts::theme_boe_identity_md() +
  scale_y_continuous(labels = label_currency()) +
  labs(x = "Firm",
       y = "GWP (£m)",
       title = "Top 5 Firms by Average Gross Written Premium") + 
  coord_flip()

top5AverageGWP %>% 
  select(-Metric) %>% 
  rename(`£mn` = Average) %>% 
  kable(caption = "Top 5 Firms by Average Gross Written Premium") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = TRUE)
  

```

```{r GWPChanges}

## Changes over time 

GWPChanges <- 
  condensed_table_changes_long %>%
  filter(Metric %in% c("GWP (£m)", "GWP % Change"), Firms %in% c(latestTop5GWP$Firms))

GWPpctChangetop5 <- 
condensed_table_changes_long %>% 
    filter(Metric == "GWP (£m) % Change", 
           Year == max(Year), !is.infinite(value)) %>% 
    slice_max(value, n = 5)

top5pctChangeOverTime  <- 
  condensed_table_changes_long %>% 
  filter(Metric == "GWP (£m) % Change", Firms %in% c(GWPpctChangetop5$Firms), !is.na(value))


# Nominal change plot 

GWPChanges %>% 
    filter(Metric == "GWP (£m)") %>% 
    ggplot(
        aes(x = Year, 
            y = value, 
            color = Firms)
    ) + 
    geom_line() + 
  theme_boe_identity_md() +
  # theme_minimal() +
  facet_wrap(~ Firms) +
  theme(
    legend.position = "none"
  ) + 
  labs(
    y = "£mns",
    title = "Top 5 GWP (£mn) nominal changes"
  ) + 
  scale_x_date(guide = guide_axis(n.dodge = 2))



# Percent change in focus chart
top5pctChangeOverTime  %>% 
    ggplot(
        aes(x = Year, 
            y = value, 
            color = Firms)
    ) + 
    geom_line() + 
  theme_boe_identity_md() + 
  facet_wrap(~ Firms, scales = "free_y") +
  theme(
    legend.position = "none"
  ) + 
  labs(
    y = "% Change",
    title = "Top 5 Gross claims incurred % changes"
  )




```

### Net Written Premium 



```{r NWP}

NWPAvg <- prevtop5Avg %>% 
  filter(Metric == "NWP (£m)") %>% 
  slice_max(Year, n = 2) 

## Latest year chart and table 



latestTop5NWP <- condensed_table_changes_long %>%
  filter(Year == max(Year),
         Metric == "NWP (£m)") %>%
  slice_max(value, n = 5)



## Plot
latestTop5NWP %>%
    ggplot(aes(x = reorder(Firms, -value),
               y = value)) +
    geom_bar(stat = "identity",
             position = position_dodge2(),
             fill = boe_brand_main$boe_aqua) +
    boeCharts::theme_boe_identity_md() +
    scale_y_continuous(labels = label_currency()) +
    labs(x = "Firm",
         y = "NWP (£m)",
         title = "Top 5 Firms by Net Written Premium") + 
    coord_flip() +
    geom_hline(yintercept = NWPAvg$Average[1], linetype = "dashed", color = "red") +
    annotate("text", x = Inf, y = NWPAvg$Average[1], label = "2020 Average (Top 5)", color = "red", hjust = -0.75, vjust = 3.5) +
    geom_hline(yintercept = NWPAvg$Average[2], linetype = "dashed", color = "yellow") +
    annotate("text", x = Inf, y = NWPAvg$Average[2], label = "2019 Average (Top 5)", color = "yellow", hjust = -0.73, vjust = 8.5)


## Table
latestTop5NWP %>% 
  select(-Metric) %>% 
  rename(`£mn` = value) %>% 
  kable(caption = "Top 5 Firms by Net Written Premium") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = TRUE)
  






```
```{r}
## Changes over time 

NWPChanges <- 
  condensed_table_changes_long %>%
  filter(Metric %in% c("NWP (£m)", "NWP % Change"), Firms %in% c(latestTop5NWP$Firms))

NWPpctChangetop5 <- 
condensed_table_changes_long %>% 
    filter(Metric == "NWP (£m) % Change", 
           Year == max(Year), !is.infinite(value)) %>% 
    slice_max(value, n = 5)

top5pctChangeOverTime  <- 
  condensed_table_changes_long %>% 
  filter(Metric == "NWP (£m) % Change", Firms %in% c(NWPpctChangetop5$Firms), !is.na(value))


# Nominal change plot 

NWPChanges %>% 
    filter(Metric == "NWP (£m)") %>% 
    ggplot(
        aes(x = Year, 
            y = value, 
            color = Firms)
    ) + 
    geom_line() + 
  theme_boe_identity_md() +
  # theme_minimal() +
  facet_wrap(~ Firms) +
  theme(
    legend.position = "none"
  ) + 
  labs(
    y = "£mns",
    title = "Top 5 NWP (£mn) nominal changes"
  ) + 
  scale_x_date(guide = guide_axis(n.dodge = 2))



# Percent change in focus chart
top5pctChangeOverTime  %>% 
    ggplot(
        aes(x = Year, 
            y = value, 
            color = Firms)
    ) + 
    geom_line() + 
  theme_boe_identity_md() + 
  facet_wrap(~ Firms, scales = "free_y") +
  theme(
    legend.position = "none"
  ) + 
  labs(
    y = "% Change",
    title = "Top 5 Gross claims incurred % changes"
  )
```



### Gross claims incurred

```{r claims}

ClaimsAvg <- prevtop5Avg %>% 
  filter(Metric == "Gross claims incurred (£m)") %>% 
  slice_max(Year, n = 2) 

## Latest year chart and table 



latestTop5Claims <- condensed_table_changes_long %>%
  filter(Year == max(Year),
         Metric == "Gross claims incurred (£m)") %>%
  slice_max(value, n = 5)



## Plot
latestTop5Claims %>%
    ggplot(aes(x = reorder(Firms, -value),
               y = value)) +
    geom_bar(stat = "identity",
             position = position_dodge2(),
             fill = boe_brand_main$boe_aqua) +
    boeCharts::theme_boe_identity_md() +
    scale_y_continuous(labels = label_currency()) +
    labs(x = "Firm",
         y = "Gross claims incurred (£m)",
         title = "Top 5 Firms by Gross claims incurred") + 
    coord_flip() +
    geom_hline(yintercept = ClaimsAvg$Average[1], linetype = "dashed", color = "red") +
    annotate("text", x = Inf, y = ClaimsAvg$Average[1], label = "2020 Average (Top 5)", color = "red", hjust = -0.75, vjust = 3.5) +
    geom_hline(yintercept = ClaimsAvg$Average[2], linetype = "dashed", color = "yellow") +
    annotate("text", x = Inf, y = ClaimsAvg$Average[2], label = "2019 Average (Top 5)", color = "yellow", hjust = -0.73, vjust = 8.5)


## Table
latestTop5Claims %>% 
  select(-Metric) %>% 
  rename(`£mn` = value) %>% 
  kable(caption = "Top 5 Firms by Gross claims incurred") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = TRUE)


## Changes over time 

claimChanges <- 
  condensed_table_changes_long %>%
  filter(Metric %in% c("Gross claims incurred (£m)", "Gross claims incurred (£m) % Change"), Firms %in% c(latestTop5Claims$Firms))

claimpctChangetop5 <- 
condensed_table_changes_long %>% 
    filter(Metric == "Gross claims incurred (£m) % Change", 
           Year == max(Year), !is.infinite(value)) %>% 
    slice_max(value, n = 5)

top5pctChangeOverTime  <- 
  condensed_table_changes_long %>% 
  filter(Metric == "Gross claims incurred (£m) % Change", Firms %in% c(claimpctChangetop5$Firms), !is.na(value))


# Nominal change plot 

claimChanges %>% 
    filter(Metric == "Gross claims incurred (£m)") %>% 
    ggplot(
        aes(x = Year, 
            y = value, 
            color = Firms)
    ) + 
    geom_line() + 
  theme_boe_identity_md() +
  # theme_minimal() +
  facet_wrap(~ Firms) +
  theme(
    legend.position = "none"
  ) + 
  labs(
    y = "£mns",
    title = "Top 5 Gross claims incurred (£mn) nominal changes"
  ) + 
  scale_x_date(guide = guide_axis(n.dodge = 2))



# Percent change in focus chart
top5pctChangeOverTime  %>% 
    ggplot(
        aes(x = Year, 
            y = value, 
            color = Firms)
    ) + 
    geom_line() + 
  theme_boe_identity_md() + 
  facet_wrap(~ Firms, scales = "free_y") +
  theme(
    legend.position = "none"
  ) + 
  labs(
    y = "% Change",
    title = "Top 5 Gross claims incurred % changes"
  )




```




### Net combined ratio

This ratio can indicate a firms profitability. A Ratio of less than 100% can indicate that firm is in profit.  

The plot here shows that of very large Net Combined Ratios indicating substantial losses - it is highly likely that these 3 datapoints are errornous and require investigation
```{r NetcombinedRatio}

# Ratio to indicate profitability of a frim 


NCR <- condensed_table_changes_long %>% 
  filter(grepl("net combined ratio", Metric, ignore.case = TRUE))

NCRtoplosses <- NCR %>% 
  filter(grepl("ratio$", Metric), !is.na(value), !is.infinite(value), Year == max(Year), value > 100)
  
NCRtoplosses %>% 
    ggplot(aes(x = reorder(Firms, -value),
               y = value,
               fill = Firms)) +
    geom_bar(stat = "identity",
             position = position_dodge2()) + 
  theme_boe_identity(legend_position = "none") + 
  labs(x = "Firm",
       y = "Net Combined Ratio",
       title = "Firms with low profitability")






## Combined NCR and NWP 


# NWPNCR <- condensed_table_changes_long %>% 
#   filter(Metric %in%  c("NWP (£m)", "Net combined ratio"))
# 
# 
# NWPNCR %>% 
#   ggplot(
#     aes(x = Year, 
#         y = value)
#   ) + 
#   geom_line()

```
## Outlier analysis 


Table with all suspected outliers - IQR method was used to determine outliers in this context. Any data points 1.5x the IQR were considered to be outliers initially, further refinement and investigations would be neccesary to understand if these are true outliers. 
```{r}

outlier_table <- outlier_detector(condensed_table)

outliers <- which(apply(outlier_table, 1, function(x) any(x == TRUE)) )

outlier_table %>% 
  DT::datatable()
  # kable() %>% 
  #   kable_styling(
  #     bootstrap_options = c("striped", "hover"),
  #     full_width = T,
  #     font_size = 10.5) %>% 
  # row_spec(outliers, background = "red")
```


```{r}

# outlier_detector(condensed_table_changes_long, "value") %>%
#   pivot_wider(names_from = Metric, values_from = value) %>% 
#   kable(caption = "Table of outliers within dataset") %>% 
#   kable_styling(bootstrap_options = c("striped", "hover"), 
#                 full_width = TRUE)




# condensed_table_changes_long %>%
#   filter(!grepl("Change", Metric, ignore.case = TRUE)) %>% 
#   ggplot(aes(
#     x = Metric, 
#     y = value
#   )) + 
#   geom_boxplot() +
#   facet_wrap(~Metric, scales = "free") + 
#   theme_minimal()


# boxplot latest
condensed_table_changes_long %>%
  filter(!grepl("Change", Metric, ignore.case = TRUE), Year == max(Year)) %>% 
  ggplot(aes(
    x = Metric, 
    y = value
  )) + 
  geom_boxplot(outlier.color = "red", ) +
  facet_wrap(~Metric, scales = "free") + 
  theme_minimal() + 
  ggtitle("Boxplot for year 2020 data by Metric")


## Scatter plot to identify outliers visually 
condensed_table_changes_long %>%
  filter(!grepl("Change", Metric, ignore.case = TRUE)) %>% 
  ggplot(
    aes(
      x = Year,
      y = value, 
      color = Firms
    )
  ) + 
  geom_point() + 
  facet_wrap(~ Metric, scales = "free", ncol = 3, ) + 
  theme_minimal() + 
  theme(legend.position = "none") +
  ggtitle("Scatter plot by Metric per year")

## Focussing on latest year 
condensed_table_changes_long %>%
  filter(!grepl("Change", Metric, ignore.case = TRUE), Year == max(Year)) %>% 
  ggplot(
    aes(
      x = Firms,
      y = value, 
      color = Metric
    )
  ) + 
  geom_point() + 
  facet_wrap(~ Metric, scales = "free", ncol = 3, ) +
  theme_minimal() + 
  theme(legend.position = "none") +
  ggtitle("Scatter plot for Metric in Year 2020")

```
  
  
  
In The above  scatterplot for the year 2020 it is clear to note that in several variable the data looks as thought it is either incorrectly calculated or simply reported incorrectly. 

SCR coverage ratio and Net combined ratio in particular stand out. 

In the boxplot graphs there are a significant number of datapoints that are considered outliers by the IQR test ( 1.5 * IQR) and hence the boxplot is displaying mainly those outliers given the figures are much larger than the average values for each class. 



  
## Machine Learning 

### K Means Clustering 

In this I will attempt to group firms together based on their Gross claims incurred, this can provide us with groups that range from high risk (highest claims incurred) to lower risk (less claims incurred)


```{python }


from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt

df = pd.read_csv("underwriting.csv")
claims = df[df['Variable'] == "Gross claims incurred (£m)"]

cluster_data = claims.pivot_table(index='Firms', columns='Year', values ='value', fill_value=0)


##Standardising the cluster data using StandardScalar 

scaler = StandardScaler()

cluster_data_scaled = scaler.fit_transform(cluster_data)


# Find optimal number of clusters 

wcss = []  # Within-cluster sum of squares
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
    kmeans.fit(cluster_data_scaled)
    wcss.append(kmeans.inertia_)
    
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method for Optimal Number of Clusters')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

```


Using the elbow method above to determine the optimal number of clusters using the Within-Cluster sum of squares (WCSS is the sum of squares of the distances of each data point in all clusters to their respective centroids) against the number of clusters. Looking for the elbow point above (where the WCSS begins to decrease at a slower rate) which represents the balance between the number of clusters and the sum of the squared distances within each clusters. 

Based on the plot above it is reasonable to choose between 3/4 clusters. For the purposes of this report I will choose 3.

```{python}

kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)
cluster_labels = kmeans.fit_predict(cluster_data_scaled)

# Adding the cluster labels to the original data
cluster_data['Cluster'] = cluster_labels

# Displaying a sample of the clustered data
cluster_data['Cluster'].head()

## Plotting scatter of previous 2 years
plt.scatter(cluster_data.iloc[:, 4], cluster_data.iloc[:,3], c=cluster_data['Cluster'], cmap='viridis')
plt.xlabel('2020')
plt.ylabel('2019')
plt.title('Gross claims incurred - grouped')
plt.show()


```
After clustering into 3 groups, comparing the years 2020 vs 2019 - we can see 3 groups on the scatterplot above which largely shows group 1 (lowest risk) tends to be majority of the firms that fall into this category where the claims incurred remain fairly low (shown here in purple). 

Group 2 , shown in yellow, tends to be firms that have a moderate levels of claims incurred and could be useful to monitor these firms in particular as they can be considered somewhat of a risk especialy those further away on the plot borderlining the group 3 firms. 

Group 3 only 2 firms are appearing here and its likely that they are outliers in the dataset so these will need further investigation. 


Whilst I've plotted the two years I would also perform the same methods on variables largely related to each other. 

## Conclusion


This report highlighted some key features to focus on when analysing the 325 insurance firms within the 2016-2020 period. 

The team should primarily focus on characteristics of firms as below: 

- Big firms with unusual changes in their Gross Written premium Year on year growth.  

- Firms with large gross claims incurred. This can indicate that firms are taking on riskier business and thus receive more claims which can lead to an unstable position. As above using the clustering techniques these have been categorised into 3 main groups. They should focus on firms that are classed within the risk group 2 and 3.  

- Firms with a large net combined ratio. Large figures above 100% could indicate that insurers are running at a loss which coupled with their SCR coverage ratios could determine how well these firms fare in the face of harsh conditions. 


## Question 3 

1. Data Ingestion and Storage

For Data ingestion, Azure Data factory could be used, its a data integration service that allows us to create and schedule ETL workflows. It seamlessly connects to various data sources such as databases or even azure blob storage. It can also handle large volumes of data for daily batch processing which are subsequently handled by automatic scheduled pipelines to ensure the latest data is ingested into the workflow without any effort required. 

For Data storage, Azures Blob storage is a perfect solution - it is a scalable and cost effective storage solution. It is designed to handle large volumnes of unstructured data - allowing any new data that becomes available to be seamlessly stored alongside existing data whether this is structured or unstructured. 


2. Data processeing and transformation


Azure Databricks:
Databricks service on Azure offers an integreated environment with Spark which can allow for big data processing and analysis. This service is typically one that is used by the Data Engineers and Data Scientists. This service can also be used to clean, further process and transform the daily data to prep it for enhanced analysis by Machine Learning models. 


Alternatively Azure ML service also offers similar features to databricks which can also be used although typically Azure ML is usually used when training models with limited data. Whilst it does provide clusters to work with the data distribution must be handled via code whereas Databricks is already designed with large data in mind. 




3. Reporting and Visualization
 Power BI:

Power BI is a suite of business analytics tools that lets you analyze data and share insights. With Power BI, you can create a range of visualizations, reports, and dashboards.
It can connect directly to data in Azure Blob Storage, and other Azure data services, providing real time visualisations and insights from the processed data and shared easily between teams and colleagues. 

Further tools: 

Power platform is a powerful suite of tools which could further enhance the user experience. Apps such as virtual agents could potentially be used to create bots that the user can interactively query the data especially where reporting tools in powerBI may not have a specific view/interest set up. 


